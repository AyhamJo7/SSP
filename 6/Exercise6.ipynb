{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Single-Channel Speech Enhancement via Wiener Filtering\n",
    "\n",
    "**Authors:** Timo Gerkmann, Kristina Tesch, Danilo Oliveira  \n",
    "**This notebook implements each step of the exercise with detailed explanations and plots.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Utilities\n",
    "Load necessary libraries, read noisy signals, define STFT/ISTFT functions, and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft, istft, get_window\n",
    "from IPython.display import Audio\n",
    "\n",
    "# -- Parameters  --\n",
    "fs, signal_white = wavfile.read('6/SpeechWhite.wav')\n",
    "_, signal_babble = wavfile.read('6/SpeechBabble.wav')\n",
    "snr_db = 10  # 10 dB input SNR as given\n",
    "frame_len = int(0.032 * fs)    # 32 ms\n",
    "frame_hop = int(0.016 * fs)    # 16 ms\n",
    "window = get_window(('hann'), frame_len, fftbins=True)\n",
    "fft_len = frame_len\n",
    "\n",
    "def compute_stft(x):\n",
    "    f, t, Z = stft(x, fs=fs, window=np.sqrt(window), nperseg=frame_len, noverlap=frame_len-frame_hop, nfft=fft_len, boundary=None)\n",
    "    return f, t, Z\n",
    "\n",
    "def compute_istft(Z):\n",
    "    _, x = istft(Z, fs=fs, window=np.sqrt(window), nperseg=frame_len, noverlap=frame_len-frame_hop, nfft=fft_len, input_onesided=True, boundary=None)\n",
    "    return x\n",
    "\n",
    "print(f\"Sampling rate: {fs} Hz, frames: {frame_len} samples, hop: {frame_hop} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute STFTs and periodograms for both noise types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Yw = compute_stft(signal_white.astype(float))\n",
    "_, _, Yb = compute_stft(signal_babble.astype(float))\n",
    "Yw_mag2 = np.abs(Yw)**2\n",
    "Yb_mag2 = np.abs(Yb)**2\n",
    "num_bins, num_frames = Yw_mag2.shape\n",
    "print(f\"STFT shapes: bins={num_bins}, frames={num_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noise Power Estimation\n",
    "We estimate noise PSD using the speech-presence probability (SPP) estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Initialization\n",
    "- **Initial noise PSD** $\\hat\\sigma_n^2[k,-1]$: use first frame periodogram (assume noise‐only).  \n",
    "- **Initial smoothed probability** $Q[k,-1]=0.5$ (uninformative prior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for SPP estimator\n",
    "theta_db = 15\n",
    "theta = 10**(theta_db/10)\n",
    "alpha_q = 0.9   # smoothing for Q\n",
    "beta_n = 0.8    # smoothing for noise PSD\n",
    "\n",
    "# Initialize matrices\n",
    "def init_noise_psd(Y_mag2):\n",
    "    sigma_n2 = Y_mag2[:,0].copy()\n",
    "    Q_prev = np.full(num_bins, 0.5)\n",
    "    return sigma_n2, Q_prev\n",
    "\n",
    "sigma_n2_w, Q_prev_w = init_noise_psd(Yw_mag2)\n",
    "sigma_n2_b, Q_prev_b = init_noise_psd(Yb_mag2)\n",
    "print(\"Initialized noise PSD and Q for white & babble cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Compute Posterior Speech-Presence Probability\n",
    "For each frame `l` and bin `k`,\n",
    "$$P(H_1|Y)=\\Bigl[1 + (1+\\theta)\\exp\\bigl(-|Y|^2/(\\hat\\sigma_n^2[l-1])\\,\\theta/(1+\\theta)\\bigr)\\Bigr]^{-1}$$\n",
    "then smoothly limit high values via $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spp_and_noise(Y_mag2, sigma_n2_init, Q_prev_init):\n",
    "    P = np.zeros_like(Y_mag2)\n",
    "    Q = np.zeros_like(Y_mag2)\n",
    "    sigma_n2 = np.zeros_like(Y_mag2)\n",
    "    sigma_n2[:,0] = sigma_n2_init\n",
    "    Q_prev = Q_prev_init.copy()\n",
    "    \n",
    "    for l in range(num_frames):\n",
    "        # posterior probability\n",
    "        post = 1 / (1 + (1+theta) * np.exp(-Y_mag2[:,l]/sigma_n2[:,l-1] * theta/(1+theta))) if l>0 else np.zeros(num_bins)\n",
    "        if l==0:\n",
    "            post = np.zeros(num_bins)\n",
    "        # smooth Q and limit\n",
    "        Q[:,l] = alpha_q*Q_prev + (1-alpha_q)*post\n",
    "        P[:,l] = np.where(Q[:,l]>0.99, np.minimum(0.99, post), post)\n",
    "        # estimate noise periodogram\n",
    "        N_hat2 = P[:,l]*sigma_n2[:,l-1] + (1-P[:,l])*Y_mag2[:,l]\n",
    "        # update noise PSD\n",
    "        sigma_n2[:,l] = beta_n*sigma_n2[:,l-1] + (1-beta_n)*N_hat2 if l>0 else sigma_n2_init\n",
    "        Q_prev = Q[:,l]\n",
    "    return P, sigma_n2\n",
    "\n",
    "# Compute for white and babble\n",
    "P_w, noise_psd_w = spp_and_noise(Yw_mag2, sigma_n2_w, Q_prev_w)\n",
    "P_b, noise_psd_b = spp_and_noise(Yb_mag2, sigma_n2_b, Q_prev_b)\n",
    "print(\"Computed SPP and noise PSD for both signals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2a) Plot Speech-Presence Probability for White-noise case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(P_w, origin='lower', aspect='auto', cmap='inferno', extent=[t[0], t[-1], f[0], f[-1]])\n",
    "plt.colorbar(label='P(H1|Y)')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.title('Speech-Presence Probability (white noise)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Where speech is present: P ≈ 1.  \n",
    "- Noise-only regions: P ≈ 0.  \n",
    "- Aligns closely with the spectrogram of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Plot Estimated Noise PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(10*np.log10(noise_psd_w+1e-12), origin='lower', aspect='auto', cmap='viridis', extent=[t[0], t[-1], f[0], f[-1]])\n",
    "plt.colorbar(label='Noise PSD [dB]')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.title('Estimated Noise PSD (white noise)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Tracks background noise floor.  \n",
    "- Some leakage where speech energy biases the estimate.  \n",
    "- Overestimation leads to speech distortion; underestimation leaves residual noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A priori SNR Estimation and Wiener Filtering\n",
    "Compute decision-directed a priori SNR and apply Wiener gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initialize clean-speech spectrum estimate: set $\\hat S[k,-1] = |Y[k,0]|^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate\n",
    "S_hat_w = np.zeros_like(Yw_mag2)\n",
    "G_w = np.zeros_like(Yw_mag2)\n",
    "# initialization\n",
    "S_hat_w[:,0] = Yw_mag2[:,0]\n",
    "G_min = 0.0\n",
    "alpha_dd = 0.5\n",
    "\n",
    "for l in range(num_frames):\n",
    "    if l>0:\n",
    "        # decision-directed estimate\n",
    "        S_hat_w[:,l] = alpha_dd*(G_w[:,l-1]**2 * Yw_mag2[:,l-1]) + (1-alpha_dd)*np.maximum(Yw_mag2[:,l] - noise_psd_w[:,l], 0)\n",
    "    xi = S_hat_w[:,l] / (noise_psd_w[:,l] + 1e-12)\n",
    "    G_w[:,l] = np.maximum(xi/(1+xi), G_min)\n",
    "\n",
    "# Apply gain to STFT\n",
    "Yw_enh = G_w * Yw\n",
    "# Inverse STFT\n",
    "enhanced_w = compute_istft(Yw_enh)\n",
    "print(\"Computed Wiener-filtered signal for white noise case.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compare Spectrograms in dB\n",
    "Use same color scale for noisy and enhanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute noisy spectrogram in dB\n",
    "Z_noisy_db = 20*np.log10(np.abs(Yw)+1e-12)\n",
    "Z_enh_db   = 20*np.log10(np.abs(Yw_enh)+1e-12)\n",
    "vmin, vmax = -80, 0\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Z_noisy_db, origin='lower', aspect='auto', vmin=vmin, vmax=vmax, extent=[t[0],t[-1],f[0],f[-1]])\n",
    "plt.title('Noisy (white)'); plt.xlabel('Time [s]'); plt.ylabel('Freq [Hz]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Z_enh_db, origin='lower', aspect='auto', vmin=vmin, vmax=vmax, extent=[t[0],t[-1],f[0],f[-1]])\n",
    "plt.title('Enhanced (α=0.5, G_min=0)'); plt.xlabel('Time [s]')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Noise floor lowered, formants clearer.  \n",
    "- Some musical noise artifacts visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Tuning and Listening\n",
    "Synthesize the enhanced signal and listen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play original & enhanced\n",
    "print(\"Original noisy (white) signal:\")\n",
    "display(Audio(signal_white, rate=fs))\n",
    "print(\"Enhanced (white) signal:\")\n",
    "display(Audio(enhanced_w.astype(np.int16), rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Observations\n",
    "- Background noise suppressed ~10 dB.  \n",
    "- Mild speech distortion, musical noise present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Vary α\n",
    "Listen for α∈{0.1,0.5,0.9}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [0.1,0.5,0.9]:\n",
    "    # recompute with new alpha\n",
    "    S_hat = np.zeros_like(Yw_mag2);\n",
    "    G = np.zeros_like(Yw_mag2)\n",
    "    S_hat[:,0]=Yw_mag2[:,0]\n",
    "    for l in range(num_frames):\n",
    "        if l>0:\n",
    "            S_hat[:,l]=a*(G[:,l-1]**2*Yw_mag2[:,l-1])+(1-a)*np.maximum(Yw_mag2[:,l]-noise_psd_w[:,l],0)\n",
    "        xi=S_hat[:,l]/(noise_psd_w[:,l]+1e-12)\n",
    "        G[:,l]=np.maximum(xi/(1+xi),G_min)\n",
    "    Yh=G*Yw; xh=compute_istft(Yh)\n",
    "    print(f\"α={a}\")\n",
    "    display(Audio(xh.astype(np.int16), rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Low α: fast noise tracking, more musical noise.  \n",
    "- High α: smoother, but residual noise remains.  \n",
    "- α≈0.7–0.8 is a good compromise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Vary $G_{min}$\n",
    "Listen for G<sub>min</sub>∈{0,0.1,0.2}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gmin in [0.0, 0.1, 0.2]:\n",
    "    S_hat = np.zeros_like(Yw_mag2); G=np.zeros_like(Yw_mag2)\n",
    "    S_hat[:,0]=Yw_mag2[:,0]\n",
    "    for l in range(num_frames):\n",
    "        if l>0:\n",
    "            S_hat[:,l]=alpha_dd*(G[:,l-1]**2*Yw_mag2[:,l-1])+(1-alpha_dd)*np.maximum(Yw_mag2[:,l]-noise_psd_w[:,l],0)\n",
    "        xi=S_hat[:,l]/(noise_psd_w[:,l]+1e-12)\n",
    "        G[:,l]=np.maximum(xi/(1+xi), gmin)\n",
    "    xh=compute_istft(G*Yw)\n",
    "    print(f\"G_min={gmin}\")\n",
    "    display(Audio(xh.astype(np.int16), rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Raising G_min retains some noise but reduces musical artifacts.  \n",
    "- G_min≈0.1–0.2 is often preferred."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
