{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c00fb3",
   "metadata": {},
   "source": [
    "# Exercise 7 Solution: Beamforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5930a9",
   "metadata": {},
   "source": [
    "## 1. STFT Setup and Loading Microphone Signals\n",
    "Load the four microphone recordings and compute STFTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft, istft, get_window\n",
    "\n",
    "# 1) Parameters\n",
    "fs, _ = wavfile.read('noisySensor.wav')  # sampling rate\n",
    "duration = None\n",
    "# Frame length 128 ms, shift 32 ms\n",
    "N = int(0.128 * fs)\n",
    "hop = int(0.032 * fs)\n",
    "\n",
    "# 2) Windows: sqrt-Hann for analysis; synthesis window scaled by 1/2\n",
    "win_analysis = np.sqrt(get_window('hann', N, fftbins=True))\n",
    "win_synthesis = win_analysis / 2\n",
    "\n",
    "# 3) Load microphone signals (4-channel file)\n",
    "fs0, data = wavfile.read('noisySensor.wav')  # shape (num_samples, 4)\n",
    "assert fs0 == fs, \"Sampling rates must match\"\n",
    "mic_signals = data.T  # shape (4, num_samples)\n",
    "\n",
    "# 4) Compute STFT for each microphone: results shape (4, freq_bins, frames)\n",
    "mic_stfts = []\n",
    "for i in range(4):\n",
    "    f, t, Zxx = stft(mic_signals[i], fs, window=win_analysis,\n",
    "                     nperseg=N, noverlap=N-hop, return_onesided=True)\n",
    "    mic_stfts.append(Zxx)\n",
    "mic_stfts = np.stack(mic_stfts, axis=0)  # (4, freq_bins, frames)\n",
    "\n",
    "print(f\"Computed STFTs: {mic_stfts.shape[0]} mics, {mic_stfts.shape[1]} freq bins, {mic_stfts.shape[2]} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbfc09",
   "metadata": {},
   "source": [
    "**Question:** Why scale the synthesis window by 1/2?\n",
    "\n",
    "**Answer:** We use sqrt-Hann windows for perfect reconstruction under 75% overlap (hop=N/4). Scaling the synthesis window by 1/2 compensates for the two overlapping analysis windows, ensuring the overlap-add sums to unity and avoids amplitude modulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e173e0",
   "metadata": {},
   "source": [
    "## 2. Delay-and-Sum Beamformer\n",
    "Implement the classical delay-and-sum beamformer in the STFT domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb4b50",
   "metadata": {},
   "source": [
    "### 2.1 Steering Vector Computation\n",
    "Compute time delays and steering vector for θ=π/4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e05bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Geometry and DOA\n",
    "c = 340        # speed of sound (m/s)\n",
    "d = 0.05       # microphone spacing (m)\n",
    "theta = np.pi/4  # arrival angle\n",
    "\n",
    "# 2) Compute time delays tau_i for each mic relative to mic0\n",
    "tau = np.array([i * d * np.cos(theta) / c for i in range(4)])  # (4,)\n",
    "\n",
    "# 3) Build steering vectors for each frequency bin k\n",
    "freq_bins = mic_stfts.shape[1]\n",
    "steering = np.zeros((4, freq_bins), dtype=complex)\n",
    "for k in range(freq_bins):\n",
    "    # frequency value\n",
    "    f_k = k * fs / N\n",
    "    steering[:, k] = np.exp(-1j * 2 * np.pi * f_k * tau)\n",
    "\n",
    "print(\"Steering vector shape:\", steering.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8873609c",
   "metadata": {},
   "source": [
    "**Question:** Why is τᵢ = i·d·cosθ / c correct?\n",
    "\n",
    "**Answer:** Under the far-field and free-field assumptions, the path difference between mic0 and mic i is i·d·cosθ. Dividing by c gives the time delay for a plane wave arriving at angle θ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b54d2a",
   "metadata": {},
   "source": [
    "### 2.2 Beamforming and Inverse STFT\n",
    "Apply delay-and-sum: Ŝ(k,l) = (1/M)·aᴴ(k)·Y(k,l), then synthesize time signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Stack STFTs: shape (4, freq_bins, frames)\n",
    "Y = mic_stfts\n",
    "\n",
    "# 2) Delay-and-sum combining\n",
    "M = 4\n",
    "freq_bins, num_frames = Y.shape[1], Y.shape[2]\n",
    "DS_spec = np.zeros((freq_bins, num_frames), dtype=complex)\n",
    "for l in range(num_frames):\n",
    "    DS_spec[:, l] = np.conj(steering[:, :]) * Y[:, :, l]\n",
    "    # sum across mics and normalize\n",
    "    DS_spec[:, l] = DS_spec[:, l].sum(axis=0) / M\n",
    "\n",
    "# 3) Inverse STFT to time domain\n",
    "_, ds_output = istft(DS_spec, fs, window=win_synthesis,\n",
    "                     nperseg=N, noverlap=N-hop, input_onesided=True)\n",
    "\n",
    "# 4) Write output WAV\n",
    "wavfile.write('ds_output.wav', fs, np.real(ds_output).astype(np.int16))\n",
    "print(\"Delay-and-sum output written to ds_output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7583c",
   "metadata": {},
   "source": [
    "**Question:** Why normalize by M?\n",
    "\n",
    "**Answer:** Dividing by M ensures unity gain for the desired direction, preventing amplitude scaling and maintaining the signal's original power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9fb42d",
   "metadata": {},
   "source": [
    "### 2.3 Spectrogram Comparison\n",
    "Plot spectrogram of mic0 and DS output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spectrogram of mic0\n",
    "f0, t0, Z0 = stft(mic_signals[0], fs, window=win_analysis,\n",
    "                  nperseg=N, noverlap=N-hop)\n",
    "# Spectrogram of DS output\n",
    "f1, t1, Z1 = stft(ds_output, fs, window=win_analysis,\n",
    "                  nperseg=N, noverlap=N-hop)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.pcolormesh(t0, f0, 20*np.log10(np.abs(Z0)+1e-12), shading='gouraud')\n",
    "plt.title('Noisy mic0'); plt.xlabel('Time [s]'); plt.ylabel('Frequency [Hz]')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.pcolormesh(t1, f1, 20*np.log10(np.abs(Z1)+1e-12), shading='gouraud')\n",
    "plt.title('Delay-and-Sum Beamformer'); plt.xlabel('Time [s]'); plt.ylabel('Frequency [Hz]')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18886102",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "- The DS output spectrogram shows reduced noise floor across frequencies.\n",
    "- Speech formants remain intact, confirming directional alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327d22c",
   "metadata": {},
   "source": [
    "## 3. MVDR Beamformer\n",
    "Implement the Minimum Variance Distortionless Response beamformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32007022",
   "metadata": {},
   "source": [
    "### 3.1 Noise Covariance and Filter Computation\n",
    "Estimate noise covariance from the first second (noise-only), then compute h(k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import solve\n",
    "\n",
    "# 1) Number of noise-only frames in first second\n",
    "frames_per_sec = int(fs / hop)\n",
    "L = frames_per_sec\n",
    "\n",
    "# 2) Compute noise covariance Phi_V(k) for each k\n",
    "Phi_V = np.zeros((freq_bins, 4, 4), dtype=complex)\n",
    "for k in range(freq_bins):\n",
    "    # accumulate Y[:,k,l] outer products\n",
    "    accum = np.zeros((4,4), dtype=complex)\n",
    "    for l in range(L):\n",
    "        yk = Y[:, k, l][:, None]  # shape (4,1)\n",
    "        accum += yk @ yk.conj().T\n",
    "    Phi_V[k] = accum / L\n",
    "\n",
    "# 3) Compute MVDR weights h(k)\n",
    "H_mvdr = np.zeros((freq_bins, 4), dtype=complex)\n",
    "for k in range(freq_bins):\n",
    "    a_k = steering[:, k]\n",
    "    # solve Phi_V[k] * x = a_k\n",
    "    x = solve(Phi_V[k], a_k)\n",
    "    H_mvdr[k] = x / (a_k.conj().T @ x)\n",
    "\n",
    "print(\"Computed MVDR filters H_mvdr with shape:\", H_mvdr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae8512",
   "metadata": {},
   "source": [
    "**Question:** Why use solve(Φ_V, a) instead of inv(Φ_V)?\n",
    "\n",
    "**Answer:** `solve` is numerically more stable and efficient than explicitly computing the inverse, reducing round-off errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43375a07",
   "metadata": {},
   "source": [
    "### 3.2 Apply MVDR and ISTFT\n",
    "Filter the STFT and reconstruct time-domain signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Apply MVDR\n",
    "MVDR_spec = np.zeros((freq_bins, num_frames), dtype=complex)\n",
    "for l in range(num_frames):\n",
    "    MVDR_spec[:, l] = np.conj(H_mvdr) * Y[:, :, l]\n",
    "    MVDR_spec[:, l] = MVDR_spec[:, l].sum(axis=0)\n",
    "\n",
    "# 2) Inverse STFT\n",
    "_, mvdr_output = istft(MVDR_spec, fs, window=win_synthesis,\n",
    "                       nperseg=N, noverlap=N-hop, input_onesided=True)\n",
    "\n",
    "# 3) Write output WAV\n",
    "wavfile.write('mvdr_output.wav', fs, np.real(mvdr_output).astype(np.int16))\n",
    "print(\"MVDR output written to mvdr_output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb5c86e",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The MVDR beamformer minimizes noise power while preserving the desired signal in direction θ, resulting in better noise suppression than DS when noise is correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695eef07",
   "metadata": {},
   "source": [
    "## 4. Performance on Different Noise Fields\n",
    "Apply both beamformers to isotropic and directional noise recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to process any multichannel file\n",
    "def beamform_and_save(filename):\n",
    "    # Load signals\n",
    "    fs_i, data_i = wavfile.read(filename)\n",
    "    mic_i = data_i.T\n",
    "    # STFT\n",
    "    Z = np.stack([stft(mic_i[i], fs_i, window=win_analysis,\n",
    "                       nperseg=N, noverlap=N-hop)[2] for i in range(4)], axis=0)\n",
    "    # DS\n",
    "    DS = np.sum(np.conj(steering[:,:,None]) * Z, axis=0) / M\n",
    "    # MVDR\n",
    "    MVDR = np.zeros_like(DS)\n",
    "    for l in range(Z.shape[2]):\n",
    "        MVDR[:,l] = np.sum(np.conj(H_mvdr) * Z[:,:,l], axis=0)\n",
    "    # ISTFT\n",
    "    _, ds_o = istft(DS, fs_i, window=win_synthesis,\n",
    "                    nperseg=N, noverlap=N-hop, input_onesided=True)\n",
    "    _, mvdr_o = istft(MVDR, fs_i, window=win_synthesis,\n",
    "                      nperseg=N, noverlap=N-hop, input_onesided=True)\n",
    "    # Save\n",
    "    base = filename.replace('.wav','')\n",
    "    wavfile.write(base + '_ds.wav', fs_i, np.real(ds_o).astype(np.int16))\n",
    "    wavfile.write(base + '_mvdr.wav', fs_i, np.real(mvdr_o).astype(np.int16))\n",
    "    return ds_o, mvdr_o\n",
    "\n",
    "# Process isotropic and directional files\n",
    "iso_ds, iso_mvdr = beamform_and_save('noisyIsotropic.wav')\n",
    "dir_ds, dir_mvdr = beamform_and_save('noisyDirectional.wav')\n",
    "\n",
    "print(\"Processed isotropic and directional noise recordings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff728a5",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "- **Uncorrelated (sensor) noise:** DS ≈ MVDR (identical) as noise is spatially white.\n",
    "- **Isotropic noise:** MVDR outperforms DS by placing nulls and reducing diffuse noise.\n",
    "- **Directional noise:** MVDR creates a spatial notch towards noise direction; DS cannot null, so residual remains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc043a6",
   "metadata": {},
   "source": [
    "### 4.1 Spectrograms Comparison\n",
    "Show spectrograms of all enhanced signals for visual comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fe11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_spec(sig, title):\n",
    "    f, t, Z = stft(sig, fs, window=win_analysis, nperseg=N, noverlap=N-hop)\n",
    "    plt.pcolormesh(t, f, 20*np.log10(np.abs(Z)+1e-12), shading='gouraud')\n",
    "    plt.title(title); plt.xlabel('Time [s]'); plt.ylabel('Freq [Hz]')\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "titles = ['Sensor DS','Sensor MVDR','Isotropic DS','Isotropic MVDR','Directional DS','Directional MVDR']\n",
    "sigs = [ds_output, mvdr_output, iso_ds, iso_mvdr, dir_ds, dir_mvdr]\n",
    "\n",
    "for i, (sig, title) in enumerate(zip(sigs, titles), 1):\n",
    "    plt.subplot(3,2,i)\n",
    "    plot_spec(sig, title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff8fc5",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "- MVDR yields deeper suppression in isotropic and directional noise.\n",
    "- DS and MVDR produce identical results for sensor noise, confirming theory.\n",
    "- Spectrograms show clearer formants and lower noise floor with MVDR in correlated-noise cases."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
